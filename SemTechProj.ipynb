{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d8e2f2",
   "metadata": {},
   "source": [
    "# Sem Tech Project Gruppe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73a058",
   "metadata": {},
   "source": [
    "## Define Company Object Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f397b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyObject:\n",
    "    def __init__(self, list_Languages, list_Lables, list_Aliases, isSubsidiaryOf=\"None\",\n",
    "                 TwitterUsernames=\"\", TwitterIDs=0, compID=0):\n",
    "        \n",
    "        self.compID=compID\n",
    "        self.list_Languages=list_Languages\n",
    "        self.list_Lables=list_Lables\n",
    "        self.list_Aliases=list_Aliases\n",
    "        self.isSubsidiaryOf=isSubsidiaryOf\n",
    "        self.TwitterUsernames=TwitterUsernames\n",
    "        self.TwitterIDs=TwitterIDs\n",
    "    \n",
    "    def __str__(self):\n",
    "        s=\"ID: \"+str(self.compID)+\" with \"+str(len(self.list_Languages))+\" languages and TwitterUsernames: \"+str(self.TwitterUsernames)\n",
    "        if(self.isSubsidiaryOf != \"null\"):\n",
    "            s+=\" with Subsidiary: \"+str(self.isSubsidiaryOf.compID)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28af07a",
   "metadata": {},
   "source": [
    "# Crawl HTML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20d8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### First Tests of HTML Extraction\n",
    "\n",
    "def AddSocialMediaToCompany(comp):\n",
    "    response = requests.get(url=(\"https://www.wikidata.org/wiki/\"+comp.compID))\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    http = soup.find_all('a', {'href':re.compile('https://twitter.com')})\n",
    "    nameList=[]\n",
    "    idList=[]\n",
    "    for i in range(0, len(http)):\n",
    "        url=http[i]['href'].rsplit('/', 1)[-1]\n",
    "        if(url.isdigit()):\n",
    "            idList.append(url)\n",
    "        else:\n",
    "            nameList.append(url)\n",
    "    comp.TwitterUsernames=nameList\n",
    "    comp.TwitterIDs=idList\n",
    "    \n",
    "    \n",
    "response = requests.get(\n",
    "\turl=\"https://www.wikidata.org/wiki/Q20716\",\n",
    ")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\n",
    "twittername = soup.find_all(\"div\", id=re.compile(\"Q20716\\$\"))\n",
    "                            \n",
    "http = soup.find_all('a', {'href':re.compile('https://twitter.com')})\n",
    "\n",
    "#print(http)\n",
    "#url = \"https://twitter.com/i/user/2381578122\"\n",
    "#print(url.rsplit('/', 1)[-1])\n",
    "#twitterNameList = [http[i] for i in range(0, len(http), 2)]\n",
    "\n",
    "nameList=[]\n",
    "idList=[]\n",
    "\n",
    "#userid = [id for in http]\n",
    "#print(http[0]['href'])\n",
    "\n",
    "for i in range(0, len(http)):\n",
    "    url=http[i]['href'].rsplit('/', 1)[-1]\n",
    "    if(url.isdigit()):\n",
    "        idList.append(url)\n",
    "    else:\n",
    "        nameList.append(url)\n",
    "#print(idList,nameList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74db2e",
   "metadata": {},
   "source": [
    "# Crawl Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7a6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def isNaN(num):\n",
    "    return num!= num\n",
    "\n",
    "def getDaughterID(comp):\n",
    "    return comp['besteht_aus']['value'].rsplit('/', 1)[-1]\n",
    "\n",
    "def crawl(compID, compMotherObject=\"null\"):\n",
    "    response = requests.get(\n",
    "        url=(\"https://www.wikidata.org/wiki/Special:EntityData/\"+compID+\".json\"))\n",
    "    data = json.loads(response.text)\n",
    "    df = pd.DataFrame(data['entities'][compID]['labels'])\n",
    "    \n",
    "    languages=df.iloc[0]\n",
    "    labels=df.iloc[1]\n",
    "    \n",
    "    df = pd.DataFrame(data['entities'][compID])\n",
    "    \n",
    "    temp = [i for i in df['aliases'] if not (isNaN(i))]\n",
    "    \n",
    "    aliases=[]\n",
    "\n",
    "    for i in temp:\n",
    "        for a in i:\n",
    "            aliases.append(a)\n",
    "    \n",
    "    # Example Accesses\n",
    "    #print(new,\"ENDE\")\n",
    "    #print(new[0]['language'])\n",
    "    #print(new[0]['value'])\n",
    "\n",
    "    \n",
    "### TODO: Get further Data from HTML\n",
    "    \n",
    "     \n",
    "    compObject = CompanyObject(languages, labels, aliases,compID=compID,\n",
    "                               TwitterUsernames=\"Unknown\", isSubsidiaryOf=compMotherObject\n",
    "                             )\n",
    "\n",
    "    AddSocialMediaToCompany(compObject)\n",
    "    print(compObject)\n",
    "    \n",
    "    return compObject\n",
    "\n",
    "#crawl('Q20716')\n",
    "\n",
    "# Länge der Liste\n",
    "#print(len(results[\"results\"][\"bindings\"]))\n",
    "\n",
    "#for result in results[\"results\"][\"bindings\"][:10]:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc13d3",
   "metadata": {},
   "source": [
    "## Get whole Company List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6151b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- 0 ------------------------\n",
      "ID: Q66 with 109 languages and TwitterUsernames: ['Boeing']\n",
      "................................\n",
      "ID: Q8793 with 47 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q374451 with 23 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q570930 with 17 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q795324 with 29 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q890212 with 23 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q961568 with 11 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q1236833 with 37 languages and TwitterUsernames: ['ulalaunch'] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q1541150 with 12 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q4937150 with 1 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "................................\n",
      "ID: Q6059912 with 2 languages and TwitterUsernames: [] with Subsidiary: Q66\n",
      "---------------- 10 ------------------------\n",
      "ID: Q67 with 113 languages and TwitterUsernames: ['Airbus', 'AirbusPRESS']\n",
      "................................\n",
      "ID: Q176856 with 13 languages and TwitterUsernames: [] with Subsidiary: Q67\n",
      "................................\n",
      "ID: Q888608 with 25 languages and TwitterUsernames: [] with Subsidiary: Q67\n",
      "................................\n",
      "ID: Q1163412 with 22 languages and TwitterUsernames: [] with Subsidiary: Q67\n",
      "................................\n",
      "ID: Q36363805 with 5 languages and TwitterUsernames: [] with Subsidiary: Q67\n",
      "We Are Done and Happy\n"
     ]
    }
   ],
   "source": [
    "# pip install sparqlwrapper\n",
    "# pip install pandas\n",
    "# https://rdflib.github.io/sparqlwrapper/\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "### Die aktuelle Query, welche zu jeder Company auch noch die SubCompanies liefert\n",
    "\n",
    "query=\"\"\"SELECT ?company ?besteht_aus WHERE {\n",
    "  ?company wdt:P31 wd:Q4830453.\n",
    "  OPTIONAL { ?company wdt:P1830 ?besteht_aus. }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "# Länge der Liste\n",
    "\n",
    "size=len(results[\"results\"][\"bindings\"])\n",
    "#print(size)\n",
    "\n",
    "#print(results[\"results\"][\"bindings\"][:10])\n",
    "\n",
    "#liste = results[\"results\"][\"bindings\"][:10]\n",
    "\n",
    "#print(liste[0])\n",
    "\n",
    "wholeCompList=[]\n",
    "#for i in range(0,size)\n",
    "#for i in range(0,100):\n",
    "i=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Change number of Iterations here:\n",
    "\n",
    "while(i<11):\n",
    "    print(\"----------------\",i,\"------------------------\")\n",
    "    id=results[\"results\"][\"bindings\"][i]['company']['value'].rsplit('/', 1)[-1]\n",
    "    \n",
    "\n",
    "    \n",
    "    list_tovisit=[]\n",
    "    list_tovisit.append(results[\"results\"][\"bindings\"][i]['besteht_aus']['value'].rsplit('/', 1)[-1])\n",
    "    \n",
    "    for j in range(i+1,size):\n",
    "        nextElem=results[\"results\"][\"bindings\"][j]\n",
    "        if (nextElem['company']['value'].rsplit('/', 1)[-1] == id):\n",
    "            list_tovisit.append(getDaughterID(nextElem))\n",
    "        else:\n",
    "            i=j\n",
    "            break;\n",
    "            \n",
    "    company = crawl(id)\n",
    "    wholeCompList.append(company)\n",
    "    for e in list_tovisit:\n",
    "        print(\"................................\")\n",
    "        wholeCompList.append(crawl(e,company))\n",
    "       # time.sleep(2)\n",
    "    \n",
    "for comp in wholeCompList:\n",
    "    ### Do Whatever you want ;)\n",
    "    pass\n",
    "print(\"We Are Done and Happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd448a63",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d483afc3",
   "metadata": {},
   "source": [
    "# Setting up the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f84be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "#load the basic structure of the ontology that was created in webprotege\n",
    "onto = get_ontology(\"file://names_onto.owl\").load()\n",
    "\n",
    "classes = []\n",
    "\n",
    "#extract the classes so we can create instances\n",
    "for cl in onto.classes():\n",
    "    classes.append(cl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c3b80",
   "metadata": {},
   "source": [
    "# Basic functions to create instances in order to fill our ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd78fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add attributes for instances when needed. Run for all aquired data.\n",
    "\n",
    "def get_Company_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Company\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_Alias_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Alias\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_Language_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Language\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_Dialect_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Dialect\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_Name_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Name\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_TikTok_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"TikTik_Username\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_Twitter_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Twitter_Username\"]\n",
    "    return cl[0](name)\n",
    "    \n",
    "def get_Youtube_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Youtube_Username\"]\n",
    "    return cl[0](name)\n",
    "\n",
    "def get_SubCompany_Instance(name):\n",
    "    cl = [c for c in classes if c.name == \"Subsidiary_company\"]\n",
    "    return cl[0](name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee303ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#never run this again unless absolutely necessary, takes a while..\n",
    "\n",
    "values = []\n",
    "owned_by = []\n",
    "companies = []\n",
    "\n",
    "for company in results[\"results\"][\"bindings\"]:\n",
    "    entity_number = company[\"company\"][\"value\"][31:] \n",
    "    try: \n",
    "        sub_number = company[\"besteht_aus\"][\"value\"][31:]  \n",
    "        owned_by.append({\"owner\": entity_number, \"owned\": sub_number})\n",
    "    except KeyError:\n",
    "        pass\n",
    "    values.append(entity_number)\n",
    "\n",
    "for value in values:\n",
    "    company = get_Company_Instance(value)\n",
    "    companies.append(company)\n",
    "\n",
    "\n",
    "for pair in owned_by:\n",
    "    if pair[\"owner\"] in values and pair[\"owned\"] in values:\n",
    "        owner = [c for c in companies if c.name == pair[\"owner\"]][0]\n",
    "        owned = [c for c in companies if c.name == pair[\"owned\"]][0]\n",
    "        owner.is_parent_company_of.append(owned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336dbf4",
   "metadata": {},
   "source": [
    "# Example on how to link created instances via properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c791adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "alias = get_Alias_Instance(\"Alias\")\n",
    "\n",
    "Name = get_Name_Instance(\"Name\")\n",
    "\n",
    "alias.belongs_to.append(Name)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44402ac7",
   "metadata": {},
   "source": [
    "# Some sample querries running on our ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76770cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of classes:\", list(default_world.sparql(\"\"\"\n",
    "           SELECT (COUNT(?x) AS ?nb)\n",
    "           { ?x a owl:Class . }\n",
    "    \"\"\")))\n",
    "\n",
    "print(\"One example class\", list(default_world.sparql(\"\"\"\n",
    "           SELECT ?x\n",
    "           { ?x rdfs:label \"Alias\" . }\n",
    "    \"\"\")))\n",
    "\n",
    "print(\"All classes with their sub-classes:\", list((default_world.sparql(\"\"\"\n",
    "           SELECT ?x ?y\n",
    "           { ?x a owl:Class . \n",
    "             ?x rdfs:subClassOf* ?y }\n",
    "    \"\"\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f31fb",
   "metadata": {},
   "source": [
    "# Using sync_reasoner to find and fix inconsistencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatically finds inconsistencies and reclassifies individuals and superclasses\n",
    "#especially helpful when circular dependencies are present \n",
    "sync_reasoner()\n",
    "\n",
    "\n",
    "#optional: use diffrent reasoner, no differences spotted yet\n",
    "#sync_reasoner_pellet() \n",
    "\n",
    "\n",
    "#optional: also taking object property values into acount\n",
    "#sync_reasoner(infer_property_values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7c095",
   "metadata": {},
   "source": [
    "# Saving changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird: owlready2 cannot overwrite a file passed into the function via the first parameter. It can only create a new files...\n",
    "\n",
    "onto.save(\"filled_names_onto4\", \"rdfxml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
