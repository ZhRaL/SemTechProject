{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d8e2f2",
   "metadata": {},
   "source": [
    "# Sem Tech Project Gruppe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc13d3",
   "metadata": {},
   "source": [
    "## Get whole Company List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6151b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206154\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q8793'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q374451'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q570930'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q795324'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q890212'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q961568'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1236833'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1541150'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q4937150'}}\n",
      "{'company': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q66'}, 'besteht_aus': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q6059912'}}\n"
     ]
    }
   ],
   "source": [
    "# pip install sparqlwrapper\n",
    "# pip install pandas\n",
    "# https://rdflib.github.io/sparqlwrapper/\n",
    "\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "### Die aktuelle Query, welche zu jeder Company auch noch die SubCompanies liefert\n",
    "\n",
    "query=\"\"\"SELECT ?company ?besteht_aus WHERE {\n",
    "  ?company wdt:P31 wd:Q4830453.\n",
    "  OPTIONAL { ?company wdt:P1830 ?besteht_aus. }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "# Länge der Liste\n",
    "print(len(results[\"results\"][\"bindings\"]))\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"][:10]:\n",
    "    print(result)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73a058",
   "metadata": {},
   "source": [
    "## Define Company Object Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38f397b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyObject:\n",
    "    def __init__(self, englishName, list_Languages, list_Lables, list_Aliases, \n",
    "                 TwitterUsername, TwitterID, jurisdiction, language, compID=0):\n",
    "        \n",
    "        self.compID=compID\n",
    "        self.englishName=englishName\n",
    "        self.list_Languages=list_Languages\n",
    "        self.list_Lables=list_Lables\n",
    "        self.list_Aliases=list_Aliases\n",
    "        self.isSubsidiaryOf=isSubsidiaryOf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28af07a",
   "metadata": {},
   "source": [
    "# Crawl HTML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f20d8e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found Language:  English\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### First Tests of HTML Extraction\n",
    "\n",
    "response = requests.get(\n",
    "\turl=\"https://www.wikidata.org/wiki/Q20716\",\n",
    ")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "languages=[]\n",
    "lables=[]\n",
    "\n",
    "table = soup.find_all(\"tr\", class_=re.compile(\"wikibase-entitytermsforlanguageview\"))\n",
    "\n",
    "englishName=table[0].parent.find(\"div\").find(\"span\").contents[0]\n",
    "\n",
    "\n",
    "for elem in table:\n",
    "    parentElement=elem.parent\n",
    "    # Add Language Name to the Array\n",
    "    languages.append(parentElement.find(\"th\").contents[0])\n",
    "    # Add Label to the other Array\n",
    "    lables.append(parentElement.find(\"div\").find(\"span\").contents[0])\n",
    "    print(\"I found Language: \",parentElement.find(\"th\").contents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74db2e",
   "metadata": {},
   "source": [
    "# Crawl Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7a6986",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#aliases = (df.iloc[0],df.iloc[1])\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m### TODO: Get further Data from HTML\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#                             languages, labels, aliases\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#                             )\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ1418\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Länge der Liste\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#print(len(results[\"results\"][\"bindings\"]))\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m10\u001b[39m]:\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mcrawl\u001b[1;34m(compID)\u001b[0m\n\u001b[0;32m     14\u001b[0m languages\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m labels\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcompID\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maliases\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32mD:\\UNIBW\\Master\\Social Media Mining\\Uebung\\MyProject\\my_venv\\lib\\site-packages\\pandas\\core\\frame.py:614\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    608\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    609\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UNIBW\\Master\\Social Media Mining\\Uebung\\MyProject\\my_venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:464\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    456\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    457\u001b[0m         x\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    461\u001b[0m     ]\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\UNIBW\\Master\\Social Media Mining\\Uebung\\MyProject\\my_venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mD:\\UNIBW\\Master\\Social Media Mining\\Uebung\\MyProject\\my_venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:635\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "def crawl(compID):\n",
    "    response = requests.get(\n",
    "        url=(\"https://www.wikidata.org/wiki/Special:EntityData/\"+compID+\".json\"))\n",
    "    data = json.loads(response.text)\n",
    "    df = pd.DataFrame(data['entities'][compID]['labels'])\n",
    "    \n",
    "    languages=df.iloc[0]\n",
    "    labels=df.iloc[1]\n",
    "    \n",
    "#   df = pd.DataFrame(data['entities'][compID]['aliases'])\n",
    "    \n",
    "#   aliases = (df.iloc[0],df.iloc[1])\n",
    "    \n",
    "### TODO: Get further Data from HTML\n",
    "    \n",
    "    \n",
    "    \n",
    "#    compObject = CompanyObject('Test',\n",
    "#                             languages, labels, aliases\n",
    "#                             )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "crawl('Q1418')\n",
    "# Länge der Liste\n",
    "#print(len(results[\"results\"][\"bindings\"]))\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"][:10]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ddf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "607ea8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "onto_path.append(\"/Users/leonhardziegler/Library/Mobile Documents/com~apple~CloudDocs/UniBw/Master/SematischeTech/Übungen/git_new\")\n",
    "#onto.save(file = \"filename or fileobj\", format = \"rdfxml\")\n",
    "onto = get_ontology(\"file://names_onto.owl\").load()\n",
    "#default_world.set_backend(filename = \"names_onto.owl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85f0faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[webprotege.stanford.edu.R1tTpXLvo8OlfGKD1B9sD8, webprotege.stanford.edu.R8ov2vaR2o6xwusUMLP6Ttc, webprotege.stanford.edu.R9Mm4K8OsE35OMG2l8lzmMB, names_onto.English, names_onto.French, names_onto.Bavarian]\n",
      "French\n"
     ]
    }
   ],
   "source": [
    "###test \n",
    "\n",
    "#company_instance = onto.owl:Company(\"Q1418\"))\n",
    "\"\"\"with onto:\n",
    "    class Language(Thing):\n",
    "        namespace = onto\n",
    "        pass\n",
    "\n",
    "with onto:\n",
    "    class Dialect(Language):\n",
    "        namespace = onto\n",
    "        pass\n",
    "\"\"\"\n",
    "\n",
    "language_instance = Language(\"French\")\n",
    "\n",
    "dialect_instance = Language(\"Bavarian\")\n",
    "\n",
    "print(list(onto.individuals()))\n",
    "\n",
    "print(language_instance.name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e794c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba719745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d869056",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example Instantiates\n",
    "\n",
    "# Example Instance of Mother Company\n",
    "NokiaMother = CompanyObject('Nokia',['Englisch','Japan'],['Nokia','JapanNokia'],'AG','More than 1000',\n",
    "                     'More than 1 Billion','Nok_CEO','Nok_CIO', 'null')\n",
    "\n",
    "# How to Access it\n",
    "print(\"Name: \",NokiaMother.englishName,\"\\n\")\n",
    "\n",
    "# Example Instance of Daughter Company\n",
    "NokiaDaughter = CompanyObject('Nokia_Daughter',['Englisch','Japan'],['NokiaDaugh','JapanNokiaDaugh'],'AG','More than 10',\n",
    "                               'More than 1 Million','Nok_CEODaugh','Nok_CIODaugh', NokiaMother)\n",
    "\n",
    "# How to Access it # Access to MotherCompany( if available)\n",
    "print(\"Name: \",NokiaDaughter.englishName,\" is a subsidiary of: \",NokiaDaughter.isSubsidiaryOf.englishName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
